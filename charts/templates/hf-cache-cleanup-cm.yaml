apiVersion: v1
kind: ConfigMap
metadata:
  name: chutes-hf-cache-cleaner
data:
  hf_cache_cleanup.py: |
    import os
    import time
    import shutil
    from huggingface_hub import scan_cache_dir

    def clean_old_cache(max_age_days=5, max_size_gb=100):
        cache_info = scan_cache_dir()
        max_size_bytes = max_size_gb * 1024 * 1024 * 1024
        cutoff_time = time.time() - (max_age_days * 24 * 3600)
        print(f"Current cache size: {cache_info.size_on_disk / 1024**3:.2f}GB")
        
        repos = sorted(cache_info.repos, key=lambda r: r.last_accessed)
        for repo in repos:
            if repo.last_accessed < cutoff_time:
                print(f"Removing old cache: {repo.repo_id} ({repo.size_on_disk / 1024**3:.2f}GB, "
                      f"last accessed: {time.strftime('%Y-%m-%d', time.localtime(repo.last_accessed))})")
                shutil.rmtree(repo.repo_path)
        
        cache_info = scan_cache_dir()
        if cache_info.size_on_disk > max_size_bytes:
            repos = sorted(cache_info.repos, key=lambda r: r.size_on_disk, reverse=True)
            for repo in repos:
                if repo.repo_path.exists():
                    print(f"Removing large cache: {repo.repo_id} ({repo.size_on_disk / 1024**3:.2f}GB)")
                    shutil.rmtree(repo.repo_path)
                    cache_info = scan_cache_dir()
                    if cache_info.size_on_disk <= max_size_bytes:
                        break

    if __name__ == "__main__":
        clean_old_cache(
            max_age_days=int(os.getenv("HF_CACHE_MAX_AGE_DAYS", "5")),
            max_size_gb=int(os.getenv("HF_CACHE_MAX_SIZE_GB", "100")),
        )
